# Function to add previous trials' data (lags) for specific history types
add_prev <- function(dat, n_hist, levels=c('l', 'r')) {
  for(hist_type in c('S', 'R')) {
    for(trial in 0:n_hist) {
      dat[,paste0(hist_type,'minus',trial)] <- factor(substr(Hmisc::Lag(dat[,hist_type], trial), 1, 1), levels=levels)
    }
  }
  return(dat)
}

# Function to plot a legend outside the main plotting area
legend_outside <- function(position = c("topright", "topleft"),
                           legend_text, fill = NULL, col = NULL, lty = NULL, lwd = NULL, pch = NULL,
                           border = NA, bty = "n",
                           inset_frac = 0.005,
                           ...) {
  position <- match.arg(position)
  
  usr <- par("usr")
  x_range <- usr[2] - usr[1]
  y_range <- usr[4] - usr[3]
  
  # Build args list for legend measurement
  legend_args <- list(x = usr[1], y = usr[4], legend = legend_text,
                      border = border, bty = bty, plot = FALSE, ...)
  
  if (!is.null(fill)) legend_args$fill <- fill
  if (!is.null(col)) legend_args$col <- col
  if (!is.null(lty)) legend_args$lty <- lty
  if (!is.null(lwd)) legend_args$lwd <- lwd
  if (!is.null(pch)) legend_args$pch <- pch
  
  # Measure legend size without plotting
  leg_info <- do.call(graphics::legend, legend_args)
  
  legend_height <- leg_info$rect$h
  legend_width <- leg_info$rect$w
  
  offset_y <- legend_height + inset_frac * y_range
  inset_x <- inset_frac * x_range
  
  par(xpd = TRUE)
  
  # Prepare args for actual legend drawing
  legend_args$x <- NULL
  legend_args$y <- NULL
  legend_args$plot <- NULL
  
  if (position == "topleft") {
    legend_args$x <- usr[1] + inset_x
    legend_args$y <- usr[4] + offset_y
    # legend_args$adj <- c(0, 0.5)
  } else if (position == "topright") {
    legend_args$x <- usr[2] - legend_width - inset_x
    legend_args$y <- usr[4] + offset_y
  # legend_args$adj <- c(0, 0.5)  # left align, vertical center
  }
  
  do.call(graphics::legend, legend_args)
  
  par(xpd = FALSE)
}

# Reverse a string
rev_str <- function(x) paste(rev(strsplit(x, "")[[1]]), collapse = "")

# Recode 'S' and 'R' columns into repetition/alternation variables
recode_RA <- function(dat) {
  for(hist_type in c('S', 'R')) {
    cname <- paste0(hist_type, 'rep')
    # Recode S and R into repetition/alternation
    tmp1 <- ifelse(as.numeric(dat[,hist_type])==1,1,-1)
    tmp2 <- Hmisc::Lag(tmp1, 1)
    dat[,cname] <- tmp1*tmp2
    dat[dat$trials==1,cname] <- 0
    dat[is.na(dat[,cname]),cname] <- 0
  }
  
  dat[,'S'] <- factor(dat$Srep, levels=c(1,-1), labels=c('R', 'A'))
  dat[,'R'] <- factor(dat$Rrep, levels=c(1,-1), labels=c('R', 'A'))
  dat[,!colnames(dat) %in% c('Srep', 'Rrep')]
}

plot_history_effects <- function(dat, pp=NULL, hist_type='S', 
                                 n_hist=3, hist_from=1, p_random=0.5, 
                                 degree=1, ...) {
  #' Plot History Effects on Reaction Times and Choices
  # 
  #' This function visualizes the effects of prior trials (history) on reaction times 
  #' and choices, with options to plot empirical data and posterior predictive data.
  #' 
  #' @param dat A dataframe containing the empirical data, formatted according to EMC2's standard.
  #' @param pp A dataframe of posterior predictive data, typically generated by the `predict()` function.
  #' @param hist_type A character string indicating the type of history to examine. 
  #'        Either 'S' for stimulus history or 'R' for response history.
  #' @param n_hist An integer specifying the number of previous trials (lags) to consider when analyzing history effects.
  #' @param hist_from An integer specifying the trial from which to start considering history. 
  #'        This defines the range of history, where the history is taken from trials `n_hist` to `hist_from`.
  #'        Default is 3:1, meaning it looks back from trial t-3 to trial t-1, and the current trial is plotted.
  #' @param p_random A numeric value between 0 and 1 that specifies the probability of random choice (typically 0.5).
  #' @param degree An integer (1 or 2) specifying the type of recency effects to analyze:
  #'        1 for first-degree recency effects, 
  #'        2 for second-degree recency effects (considering alternating or repetitive patterns in history).
  #' @param ... Additional optional arguments that are passed to the `plot()` function for customization.
  
  opts <- list(...)
  
  # Handle multiple degrees (if needed)
  if(length(degree) > 1) {
    par(mfrow=c(2,2))
    for(degree_ in degree) {
      plot_history_effects(dat=dat, pp=pp, hist_type=hist_type, n_hist=n_hist, 
                           p_random=p_random, degree=degree_, nopar=TRUE, ...)
    }
    return(invisible(NULL))
  } else {
    if(!'nopar' %in% names(opts)) par(mfcol=c(1,2))
  }
  
  # Recode data for degree 2 if necessary
  if(degree == 2) {
    dat <- recode_RA(dat)
    dat <- dat[!is.na(dat$S),]
    
    if(!is.null(pp)) {
      pp <- recode_RA(pp)
      pp <- pp[!is.na(pp$S),]
    }
  }
  
  # Add previous trial data (lags)
  dat <- add_prev(dat, n_hist=n_hist, levels=sapply(levels(dat$S), substr, 1, 1))
  if(!is.null(pp)) {
    pp <- add_prev(pp, n_hist=n_hist, levels=sapply(levels(dat$S), substr, 1, 1))
  }

  # Prepare labels
  is_Rone_label <- is_Rone <- levels(dat$R)[1]
  is_Rtwo_label <- is_Rtwo <- levels(dat$R)[2]
  is_Sone_label <- is_Sone <- levels(dat$S)[1]
  
  # Define choice and stimulus variables
  dat$choice <- dat$R==is_Rone
  dat$stim <- dat$S==is_Sone
  if(!is.null(pp)) {
    pp$choice <- pp$R==is_Rone
    pp$stim <- pp$S==is_Sone
  }
  
  if(degree == 2) {
    is_Rone_label <- ifelse(is_Rone=='R', 'Rep.', 'Alt.') 
    is_Rtwo_label <- ifelse(is_Rtwo=='R', 'Rep.', 'Alt.') 
    is_Sone_label <- ifelse(is_Sone=='R', 'Rep.', 'Alt.') 
  }
  
  # Remove trials with NA values for previous history (first trials)
  dat <- dat[!is.na(dat[,paste0('Sminus', n_hist)]),]
  if(!is.null(pp)) {
    pp <- pp[!is.na(pp[,paste0('Sminus', n_hist)]),]
  }
  
  # Create the previous history string (lags)
  colN <- toupper(substr(hist_type,1,1))
  prevD <- prevPP <- NULL
  for(trial in hist_from:n_hist) {
    prevD <- paste0(prevD, dat[,paste0(colN,'minus',trial)])
    if(!is.null(pp)) {
      prevPP <- paste0(prevPP, pp[,paste0(colN,'minus',trial)])
    }
  }
  dat$prev <- prevD
  if(!is.null(pp)) {
    pp$prev <- prevPP
  }
  
  # RTs ~ history: Aggregate by subject, then across subjects
  agg1 <- aggregate(rt~subjects*R*prev, dat, mean)
  agg2 <- aggregate(rt~R*prev, agg1, mean)

  ylim1 <- range(c(agg2$rt))
  if(!is.null(pp)) {
    # pp. Aggregate by subject, then across subjects, then CI across posteriors
    agg1pp <- aggregate(rt~postn*subjects*R*prev, pp, mean)
    agg2pp <- aggregate(rt~postn*R*prev, agg1pp, mean)
    agg3pp <- aggregate(rt~R*prev, agg2pp, quantile, c(0.025, .5, 0.975))
    ylim1 <- range(c(agg2$rt,agg3pp$rt))
  }
  
  # 1. RT ~ history plot
  x <- 1:length(agg2$prev[agg2$R==is_Rone])
  plot(x,agg2$rt[agg2$R==is_Rone], pch=4, lwd=1, xaxt='n', ylab='RT', xlab=paste0('Previous ', hist_type), ylim=ylim1)
  points(x,agg2$rt[agg2$R!=is_Rone], pch=4, col=2, lwd=1)
  
  # Reverse labels for axis
  labels_rev <- sapply(agg2$prev[agg2$R!=is_Rone], rev_str)
  axis(side=1, at=x, labels=labels_rev, las=3)
  
  # Add legends
  if(!is.null(pp)) {
    legend_outside('topleft', legend_text=c('data', 'model'), col=c(1,1), lwd=c(NA,1), lty=c(NA,1), pch=c(4,NA), bty = "n")
  } else {
    legend_outside('topleft', legend_text=c('data'), col=c(1), lwd=c(1), lty=c(1), pch=c(4), bty = "n")
  }
  legend_outside('topright', legend_text=c(paste0('R=', is_Rone_label), paste0('R=', is_Rtwo_label)), fill=c(1,2), border=NA, bty='n')
  
  # Add confidence intervals and lines for model (if pp is provided)
  if(!is.null(pp)) {
    arrows(x0=x, y0=agg3pp$rt[agg3pp$R==is_Rone,1], y1=agg3pp$rt[agg3pp$R==is_Rone,3], angle=90, code=3, length=0.025, col=1)
    arrows(x0=x, y0=agg3pp$rt[agg3pp$R!=is_Rone,1], y1=agg3pp$rt[agg3pp$R!=is_Rone,3], angle=90, code=3, length=0.025, col=2)
    lines(x, agg3pp$rt[agg3pp$R==is_Rone,2], col=1)
    lines(x, agg3pp$rt[agg3pp$R!=is_Rone,2], col=2)
  } else {
    lines(x,agg2$rt[agg2$R==is_Rone])
    lines(x,agg2$rt[agg2$R!=is_Rone], col=2)
  }
  
  # 2. Choice ~ history
  agg3 <- aggregate(choice~subjects*prev, dat, mean)
  agg4 <- aggregate(choice~prev, agg3, mean)
  
  if(!is.null(pp)) {
    agg3pp <- aggregate(choice~postn*subjects*prev, pp, mean)
    agg4pp <- aggregate(choice~prev*postn, agg3pp, mean)
    agg5pp <- aggregate(choice~prev, agg4pp, quantile, c(0.025,.5, 0.975))
  }
  
  agg5 <- aggregate(stim~subjects*prev, dat, mean)
  agg6 <- aggregate(stim~prev, agg5, mean)
  
  if(!is.null(pp)) {
    ylim2 <- range(c(range(agg4$choice), range(agg5pp$choice), range(agg6$stim)))
  } else {
    ylim2 <- range(c(range(agg4$choice), range(agg6$stim)))
  }
  x <- 1:length(agg4$prev)
  plot(x,agg4$choice, type='n', pch=4, lwd=1, xaxt='n', ylab=paste0('P (', is_Rone_label, ')'), xlab=paste0('Previous ', hist_type), ylim=ylim2)
  abline(h=p_random, lty=2)
  # PP
  if(!is.null(pp)) {
    arrows(x0=x, y0=agg5pp[,2][,1], y1=agg5pp[,2][,3], angle=90, code=3, length=0.025, col=1)
    lines(x=x, y=agg5pp[,2][,2], col=1)
  } else {
    lines(x,agg4$choice, col=1)
  }
  
  # 4. Plot Stimulus ~ history
  x <- 1:length(agg6$prev)
  points(x, agg6$stim, pch=20, lwd=1, col=2) # 
  points(x, agg4$choice, pch=4, lwd=1)  # plot again to overwrite filled circle
  
  labels_rev <- sapply(agg6$prev, rev_str)
  axis(side=1, at=x, labels=labels_rev, las=3)
  if(!is.null(pp)) {
    legend_outside('topleft', legend_text=c('data', 'model'), col=c(1,1), lwd=c(NA,1), lty=c(NA,1), pch=c(4,NA), bty = "n")
  } else {
    legend_outside('topleft', legend_text=c('data'), col=c(1), lwd=c(1), lty=c(1), pch=c(4), bty = "n")
  }
  legend_outside('topright', legend_text=c('stimulus'), pch=c(20), col=2, border=NA, bty='n')
}

#' Plot Post-Error Effects (PES)
#'
#' @param data_pes Data frame with observed PES values.
#' @param pp_pes_ci Data frame with posterior predictive intervals.
#' @param mean_rt Optional mean RT for reference line.
#' @param rt_measure Measure to plot (default: 'rtabs').
#' @param ... arguments passed onto plot
#' @export
plot_pes <- function(
    data_pes,
    pp_pes_ci,
    mean_rt = NULL,
    rt_measure = 'rtabs',
    ...
) {
  stopifnot(!is.null(data_pes), !is.null(pp_pes_ci))
  
  dots <- EMC2:::add_defaults(list(...), 
                              xlab = 'Trial relative to error',
                              main = '',
                              ylim = NULL,
                              ylab = 'RT (s)')
  
  # Filter data on rt_measure (usually 'rtabs' = absolute rt)
  data_vals <- data_pes[data_pes$measure == rt_measure, ]
  pp_vals <- pp_pes_ci[pp_pes_ci$measure == rt_measure, ]
  
  # Compute y limits
  all_values <- c(pp_vals$value, data_vals$value)
  #ylim <- dots$ylim
  if (is.null(dots$ylim)) {
    dots$ylim <- range(all_values, na.rm = TRUE) * c(0.95, 1.05)
  }
  
  # empty plot
  xs <- unique(data_vals$trialNposterror)
  dots$x <- dots$y <- xs
  dots$type <- dots$xaxt <- 'n'
  dots$xlim <- range(xs) + c(-0.25, 0.25)
  do.call(plot, dots)
  
  axis(side = 1, at = xs)
  if (!is.null(mean_rt)) abline(h = mean_rt, col = 'grey', lty = 2)
  abline(v = 0, lty = 2, col = 'grey')
  
  # Data points
  points(data_vals$trialNposterror, data_vals$value, pch = 4, lwd = 1)
  
  # Posterior predictive intervals
  arrows(
    x0 = pp_vals$trialNposterror,
    y0 = pp_vals$value[, 1],
    y1 = pp_vals$value[, 3],
    angle = 90, code = 3, length = 0.02, lwd = 1, col = 1
  )
  lines(pp_vals$trialNposterror, pp_vals$value[, 2], col = 1)
  
  legend(
    'topleft', legend = c('data', 'model'),
    lwd = c(NA, 1), lty = c(NA, 1), col = c(1, 1), pch = c(4, NA), bty = 'n'
  )
}

plot_error_effects <- function(dat, pp, n_cores = 1, ...) {
  #' Plot Error-related Effects
  #'
  #' @param dat Data frame with observed data.
  #' @param pp Data frame with posterior predictive data.
  #' @param cores Number of cores for parallel computation.
  #' @param ... further arguments passed onto plot
  #' @returns invisibly returns the error-related effects of both the data and posterior predictives
  #' 
  # ensure accuracy is in both dat and pp
  dat$accuracy <- if (!'accuracy' %in% names(dat)) dat$S == dat$R else dat$accuracy
  pp$accuracy <- if (!'accuracy' %in% names(pp)) pp$S == pp$R else pp$accuracy
  
  # obtain error-related effects from data and pps
  data_pes <- get_error_effects(dat)
  pp_pes <- get_error_effects(pp, mc_cores = n_cores)
  
  # plot
  plot_pes(
    data_pes = data_pes$average,
    pp_pes_ci = pp_pes$average,
    mean_rt = mean(aggregate(rt ~ subjects, dat, mean)[, 2]),
    ...
  )
  
  invisible(list(data_pes=data_pes, pp_pes=pp_pes))
}


get_post_pre_difference <- function(dat, rt_col = 'rt', trial_range = c(-3, 7)) {
  #' Compute Post-Pre Error RT Differences and Absolute RTs on each trial
  #' relative to an error trial, in the range of `trial_range`
  #'
  #' RT difference is currently unused in the plots, which only plot absolute RT.
  #'
  #' @param dat Data frame with trial data.
  #' @param rt_col Name of RT column.
  #' @param trial_range Range of trials to consider.
  #' @return Data frame with RT differences and absolute RTs.
  #' @export
  errors <- dat$accuracy == 0
  
  # Remove first and last trial per participant
  trial_range_by_sub <- aggregate(trials ~ subjects, dat, range)
  dat$exclude_trial <- FALSE
  for (subject in unique(trial_range_by_sub$subjects)) {
    exclude_trials <- trial_range_by_sub[trial_range_by_sub$subjects == subject, 'trials']
    dat[dat$subjects == subject, 'exclude_trial'] <- dat[dat$subjects == subject, 'trials'] %in% exclude_trials
  }
  errors <- errors & !dat$exclude_trial
  error_idx <- which(errors)
  
  # RT difference post-pre
  rtdf <- data.frame(
    trialNposterror = 1,
    probs = 'mean',
    measure = 'rt',
    value = mean(dat[error_idx + 1, rt_col] - dat[error_idx - 1, rt_col], na.rm = TRUE)
  )
  
  # Absolute RTs from trials ~-3,7
  rtabsdf <- do.call(rbind, lapply(seq(trial_range[1], trial_range[2]), function(trialNposterror) {
    trial_idx <- error_idx + trialNposterror
    trial_idx <- trial_idx[trial_idx > 0]
    if (trialNposterror != 0) trial_idx <- trial_idx[!trial_idx %in% error_idx]
    data.frame(
      trialNposterror = trialNposterror,
      probs = 'mean',
      measure = 'rtabs',
      value = mean(dat[trial_idx, rt_col], na.rm = TRUE)
    )
  }))
  
  rbind(rtabsdf, rtdf)
}

get_error_effects <- function(dat, mc_cores = 1) {
  #' Compute Error Effects
  #' 
  #' Wrapper function that calls get_post_pre_difference for each subject (in data)
  #' and each subject/postn-combination (in posterior predictives)
  #' and then aggregates the result to get a group-wise average
  #' 
  #' @param dat Data frame with trial data.
  #' @param mc_cores Number of cores for parallel computation.
  #' @return List with average and subject-level effects.
  #' @export
  is_data <- !'postn' %in% names(dat)
  if(is_data) dat$postn <- 1
  if(is_data & !'trials' %in% names(dat)) dat <- EMC2:::add_trials(dat)

  postpre <- expand.grid(postn = unique(dat$postn), subjects = unique(dat$subjects))
  diffs <- parallel::mclapply(seq_len(nrow(postpre)), function(x) {
    subject <- postpre[x, 'subjects']
    postn <- postpre[x, 'postn']
    out <- get_post_pre_difference(dat[dat$subjects == subject & dat$postn == postn, ])
    out$subjects <- subject
    out$postn <- postn
    out
  }, mc.cores = mc_cores)
  diffs <- do.call(rbind, diffs)
  
  if (is_data) {
    avg <- aggregate(value ~ measure + probs + trialNposterror, diffs, mean)
  } else {
    avg <- aggregate(
      value ~ measure + probs + trialNposterror,
      aggregate(value ~ measure + probs + trialNposterror + postn, diffs, mean),
      function(x) quantile(x, c(0.025, 0.5, 0.975))
    )
  }
  
  list(average = avg, diffs = diffs)
}


# ## Post-error effects
# plotPES <- function(data_PES=NULL,
#                     pp_PES_CI=NULL,
#                     mean_rt=NULL,
#                     xlab='Trial relative to error',
#                     rtmeasure='rtabs',
#                     main='', ylim=NULL,
#                     ylab='RT (s)') {
#   
#   ## Plot
#   if(is.null(ylim)) ylim <- range(c(pp_PES_CI[pp_PES_CI$measure==rtmeasure,'value'],
#                                     data_PES[data_PES$measure==rtmeasure,'value']))
#   ylim <- ylim*c(.95, 1.05)
#   xs <- unique(data_PES[data_PES$measure==rtmeasure, 'trialNposterror'])
#   
#   plot(xs, xs, type='n', xlab=xlab, ylab=ylab,  xaxt='n', ylim=ylim, main=main, xlim=range(xs)+c(-.25, .25))
#   
#   axis(side=1, at=xs)
#   if(!is.null(mean_rt)) abline(h=mean_rt, col=par()$col, lty=2)
#   abline(v=0, lty=2, col=par()$col)
#   
#   ## data
#   points(data_PES[data_PES$measure==rtmeasure,'trialNposterror'],
#          data_PES[data_PES$measure==rtmeasure,'value'], pch=4, lwd=1)
#   
#   ## posterior predictives
#   arrows(x0=pp_PES_CI[pp_PES_CI$measure==rtmeasure,'trialNposterror'],
#          y0=pp_PES_CI[pp_PES_CI$measure==rtmeasure,'value'][,1],
#          y1=pp_PES_CI[pp_PES_CI$measure==rtmeasure,'value'][,3],
#          angle=90, code=3, length=.02, lwd=1, col=1)
#   xs <- pp_PES_CI[pp_PES_CI$measure==rtmeasure,'trialNposterror']
#   lines(xs, pp_PES_CI[pp_PES_CI$measure==rtmeasure,'value'][,2], col=1)
#   legend('topleft', c('data', 'model'), lwd=c(NA,1), lty=c(NA,1), col=c(1,1), pch=c(4,NA), bty='n')
# }
# 
# plot_error_effects <- function(dat, pp, cores=10) {
#   if(!'accuracy' %in% colnames(dat)) dat$accuracy <- dat$S==dat$R
#   if(!'accuracy' %in% colnames(pp)) pp$accuracy <- pp$S==pp$R
#   
#   data_PES <- getErrorEffects(dat)
#   pp_PES <- getErrorEffects(pp, mc.cores=cores)
#   
#   par(mfrow=c(1,1))
#   plotPES(data_PES=data_PES$average, pp_PES=pp_PES$average,
#           mean_rt=mean(aggregate(rt~subjects,dat,mean)[,2]),
#           main='')
# }
# 
# plotPESBySubject <- function(data_PES=NULL,
#                              pp_PES_CI=NULL, 
#                              orderSubjects=TRUE,
#                              xlab='Trial relative to error',
#                              rtmeasure='rt',
#                              main='', 
#                              ylim=NULL,
#                              plotAxisTickLabels=TRUE,
#                              ylab='RT difference (post-pre error)') {
#   
#   pp_PES_CI <- pp_PES_CI[pp_PES_CI$probs %in% c('mean', '0.5'),]
#   data_PES <- data_PES[data_PES$probs %in% c('mean', '0.5'),]
#   
#   ## plot all subjects
#   idx <- 1:nrow(data_PES)
#   if(is.null(ylim)) ylim <- range(c(pp_PES_CI[pp_PES_CI $measure=='rt','value'],
#                                     data_PES[data_PES $measure=='rt','value']))
#   
#   if(orderSubjects) {
#     data_PES$subjects <- as.numeric(data_PES$subjects)
#     pp_PES_CI$subjects <- as.numeric(pp_PES_CI $subjects)
#     tmp <- data_PES[data_PES$probs=='mean'& data_PES$measure=='rt'&data_PES$trialNposterror==1,]
#     mapping <- data.frame(plotOrder=1:nrow(tmp), subjects=as.numeric(tmp[order(tmp$value),'subjects']))
#     data_PES <- merge(data_PES, mapping)
#     pp_PES_CI <- merge(pp_PES_CI, mapping)
#     data_PES$subjects <- data_PES$plotOrder
#     pp_PES_CI$subjects <- pp_PES_CI$plotOrder
#   }
#   xs <- as.numeric(unique(data_PES$subjects))
#   plot(xs, xs, type='n', xlab=xlab, ylab=ylab,  xaxt='n', ylim=ylim, main=main, xlim=range(xs)+c(-.25, +.25))
#   abline(h=0, lty=2, col='grey')
#   if(plotAxisTickLabels) {
#     axis(side=1, at=xs, labels=unique(data_PES$subjects))
#   }
#   
#   ## data
#   points(as.numeric(data_PES[data_PES$measure=='rt'&data_PES$trialNposterror==1,'subjects']),
#          data_PES[data_PES$measure=='rt'&data_PES$trialNposterror==1,'value'], pch=4, lwd=2)
#   
#   ## PP
#   arrows(x0=as.numeric(pp_PES_CI[pp_PES_CI$measure=='rt'& pp_PES_CI$trialNposterror==1,'subjects']),
#          y0= pp_PES_CI[pp_PES_CI$measure=='rt'&pp_PES_CI$trialNposterror==1,'value'][,1],
#          y1= pp_PES_CI[pp_PES_CI$measure=='rt'&pp_PES_CI$trialNposterror==1,'value'][,3],
#          angle=90, code=3, length=.02, lwd=2, col=2)
#   xs <- as.numeric(pp_PES_CI[pp_PES_CI $measure=='rt'&pp_PES_CI$trialNposterror==1,'subjects'])
#   ys <- pp_PES_CI[pp_PES_CI $measure=='rt'& pp_PES_CI$trialNposterror==1,'value'][,2]
#   lines(xs[order(xs)], ys[order(xs)], lty=1,col=2)
# }
# 
# 
# getPostPreDifference <- function(dat, rtcolname='rt', trialRange=c(-3,7)) {
#   errors <- dat$accuracy == 0
#   ## remove first trial (per participant) and last trial (per participant)
#   trialRangeBySub <- aggregate(trials~subjects, dat, range)
#   
#   dat$exclude_trial <- FALSE
#   for(subject in unique(trialRangeBySub$subjects)) {
#     ## don't include errors on the first and last trial; can't calculate post-error slowing because of lack of a pre / post error trial
#     dat[dat$subjects==subject,'exclude_trial'] = dat[dat$subjects==subject,'trials'] %in% trialRangeBySub[trialRangeBySub$subjects==subject,'trials']
#   }
#   errors <- errors & !dat$exclude_trial
#   errors <- which(errors)
#   
#   # RT difference post-pre
#   rtdf <- expand.grid(trialNposterror=1, probs='mean', measure='rt', value=NA)
#   rtdf[rtdf$trialNposterror==1,'value'] <- mean(dat[errors+1,rtcolname] - dat[errors-1,rtcolname])
#   
#   # Absolute RTs from trials ~-3,7
#   rtabsdf <- expand.grid(trialNposterror=seq(trialRange[1],trialRange[2]), probs='mean', measure='rtabs', value=NA)
#   for(trialNposterror in seq(trialRange[1],trialRange[2])) {
#     trialIdx <- errors+trialNposterror
#     trialIdx <- trialIdx[trialIdx>0]  ## remove potential trial numbers below 0
#     if(trialNposterror != 0) trialIdx <- trialIdx[!trialIdx %in% errors]  ## only inspect accurate responses, dont include errors in pre/post error trials
#     rtabsdf[rtabsdf$trialNposterror==trialNposterror,'value'] <- mean(dat[trialIdx,rtcolname], na.rm=TRUE)
#   }
#   
#   return(rbind(rtabsdf, rtdf))
# }
# 
# getErrorEffects <- function(dat, mc.cores=1) {
#   is_data <- FALSE
#   if(!'postn' %in% colnames(dat)) {
#     dat$postn <- 1
#     is_data <- TRUE
#   }
#   postpre <-  data.frame(expand.grid(postn=unique(dat$postn), subjects=unique(dat$subjects)))
#   diffs = parallel::mclapply(1:nrow(postpre),
#                              function(x) {
#                                subject <- postpre[x,'subjects']
#                                postn <- postpre[x,'postn']
#                                out <- getPostPreDifference(dat[dat$subjects==subject&dat$postn==postn,])
#                                out$subjects <- subject
#                                out$postn <- postn
#                                out
#                              }, mc.cores=mc.cores)
#   diffs <- do.call(rbind, diffs)
#   
#   if(is_data) {
#     # no postn, so only 1 value -- no CI over posterior predictives possible
#     avg <- aggregate(value~measure*probs*trialNposterror, diffs, mean)
#   } else {
#     avg <- aggregate(value~measure*probs*trialNposterror,
#                      aggregate(value~measure*probs*trialNposterror*postn, diffs, mean), 
#                      quantile, c(0.025, 0.5, 0.975))
#   }
#   
#   return(list(average=avg,diffs=diffs))
# }
